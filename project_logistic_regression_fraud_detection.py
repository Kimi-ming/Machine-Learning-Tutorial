"""
çœŸå®é¡¹ç›®æ¡ˆä¾‹ï¼šä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹ç³»ç»Ÿ
ä½¿ç”¨é€»è¾‘å›å½’è¯†åˆ«å¼‚å¸¸äº¤æ˜“

é¡¹ç›®èƒŒæ™¯ï¼š
é“¶è¡Œæ¯å¤©å¤„ç†æ•°ç™¾ä¸‡ç¬”ä¿¡ç”¨å¡äº¤æ˜“ï¼Œå…¶ä¸­å°‘æ•°å¯èƒ½æ˜¯æ¬ºè¯ˆäº¤æ˜“ã€‚
éœ€è¦ä¸€ä¸ªå®æ—¶æ£€æµ‹ç³»ç»Ÿæ¥è¯†åˆ«å¯ç–‘äº¤æ˜“ï¼Œä¿æŠ¤å®¢æˆ·èµ„é‡‘å®‰å…¨ã€‚

æ•°æ®è¯´æ˜ï¼š
- äº¤æ˜“é‡‘é¢ï¼ˆå…ƒï¼‰
- äº¤æ˜“æ—¶é—´ï¼ˆå°æ—¶ï¼Œ0-23ï¼‰
- è·ç¦»ä¸Šæ¬¡äº¤æ˜“çš„æ—¶é—´ï¼ˆå°æ—¶ï¼‰
- è·ç¦»å¸¸ç”¨åœ°ç‚¹çš„è·ç¦»ï¼ˆå…¬é‡Œï¼‰
- å•†æˆ·ç±»å‹é£é™©è¯„åˆ†ï¼ˆ0-1ï¼‰
- æ˜¯å¦å¢ƒå¤–äº¤æ˜“ï¼ˆ0/1ï¼‰
- æ˜¯å¦æ¬ºè¯ˆï¼š0=æ­£å¸¸ï¼Œ1=æ¬ºè¯ˆï¼ˆç›®æ ‡å˜é‡ï¼‰

å­¦ä¹ ç›®æ ‡ï¼š
1. ç†è§£äºŒåˆ†ç±»é—®é¢˜çš„å®é™…åº”ç”¨
2. å­¦ä¹ å¤„ç†ä¸å¹³è¡¡æ•°æ®é›†
3. æŒæ¡åˆ†ç±»æ¨¡å‹çš„è¯„ä¼°æŒ‡æ ‡
4. äº†è§£ç²¾ç¡®ç‡ã€å¬å›ç‡çš„æƒè¡¡
"""

import random
import math

try:
    import numpy as np
    HAS_NUMPY = True
except ImportError:
    HAS_NUMPY = False
    print("æç¤ºï¼šå»ºè®®å®‰è£… numpy ä»¥è·å¾—æ›´å¥½æ€§èƒ½")


def sigmoid(x):
    """Sigmoidæ¿€æ´»å‡½æ•°"""
    if x > 500:
        return 1.0
    elif x < -500:
        return 0.0
    return 1.0 / (1.0 + math.exp(-x))


class FraudDetector:
    """
    ä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹å™¨
    åŸºäºé€»è¾‘å›å½’çš„äºŒåˆ†ç±»æ¨¡å‹
    """

    def __init__(self, learning_rate=0.01, max_iterations=1000, threshold=0.5):
        """
        åˆå§‹åŒ–æ¬ºè¯ˆæ£€æµ‹å™¨
        learning_rate: å­¦ä¹ ç‡
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        threshold: åˆ†ç±»é˜ˆå€¼ï¼ˆé»˜è®¤0.5ï¼Œå¯è°ƒæ•´ä»¥å¹³è¡¡ç²¾ç¡®ç‡å’Œå¬å›ç‡ï¼‰
        """
        self.learning_rate = learning_rate
        self.max_iterations = max_iterations
        self.threshold = threshold
        self.weights = None
        self.bias = 0
        self.cost_history = []
        self.feature_names = []

        # ç”¨äºæ ‡å‡†åŒ–
        self.feature_means = []
        self.feature_stds = []

    def standardize_features(self, X, fit=True):
        """ç‰¹å¾æ ‡å‡†åŒ–"""
        if HAS_NUMPY:
            X = np.array(X)
            if fit:
                self.feature_means = np.mean(X, axis=0)
                self.feature_stds = np.std(X, axis=0) + 1e-8
            return (X - self.feature_means) / self.feature_stds
        else:
            if fit:
                n_features = len(X[0])
                self.feature_means = [sum(row[j] for row in X) / len(X) for j in range(n_features)]
                self.feature_stds = []
                for j in range(n_features):
                    variance = sum((row[j] - self.feature_means[j]) ** 2 for row in X) / len(X)
                    self.feature_stds.append(math.sqrt(variance) + 1e-8)

            X_normalized = []
            for row in X:
                normalized_row = [(val - mean) / std for val, mean, std in
                                 zip(row, self.feature_means, self.feature_stds)]
                X_normalized.append(normalized_row)
            return X_normalized

    def fit(self, X, y, feature_names=None):
        """
        è®­ç»ƒæ¨¡å‹
        X: ç‰¹å¾çŸ©é˜µ
        y: æ ‡ç­¾ (0=æ­£å¸¸, 1=æ¬ºè¯ˆ)
        """
        if feature_names:
            self.feature_names = feature_names

        # æ ‡å‡†åŒ–ç‰¹å¾
        X_normalized = self.standardize_features(X, fit=True)

        if HAS_NUMPY:
            X_normalized = np.array(X_normalized)
            y = np.array(y)
            n_samples, n_features = X_normalized.shape
            self.weights = np.zeros(n_features)

            # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
            n_fraud = np.sum(y == 1)
            n_normal = np.sum(y == 0)

            print(f"\nå¼€å§‹è®­ç»ƒæ¬ºè¯ˆæ£€æµ‹æ¨¡å‹...")
            print(f"æ ·æœ¬æ•°é‡: {n_samples} (æ­£å¸¸: {n_normal}, æ¬ºè¯ˆ: {n_fraud})")
            print(f"æ¬ºè¯ˆç‡: {n_fraud/n_samples*100:.2f}%")
            print(f"å­¦ä¹ ç‡: {self.learning_rate}, è¿­ä»£æ¬¡æ•°: {self.max_iterations}")
            print("-" * 60)

            # æ¢¯åº¦ä¸‹é™
            for iteration in range(self.max_iterations):
                # è®¡ç®—é¢„æµ‹æ¦‚ç‡
                z = np.dot(X_normalized, self.weights) + self.bias
                y_pred_prob = 1 / (1 + np.exp(-np.clip(z, -500, 500)))

                # è®¡ç®—äº¤å‰ç†µæŸå¤±
                epsilon = 1e-8
                cost = -np.mean(y * np.log(y_pred_prob + epsilon) +
                               (1 - y) * np.log(1 - y_pred_prob + epsilon))
                self.cost_history.append(cost)

                # è®¡ç®—æ¢¯åº¦
                dw = (1 / n_samples) * np.dot(X_normalized.T, (y_pred_prob - y))
                db = (1 / n_samples) * np.sum(y_pred_prob - y)

                # æ›´æ–°å‚æ•°
                self.weights -= self.learning_rate * dw
                self.bias -= self.learning_rate * db

                # æ‰“å°è¿›åº¦
                if iteration % 100 == 0:
                    y_pred = (y_pred_prob >= self.threshold).astype(int)
                    accuracy = np.mean(y_pred == y)
                    print(f"è¿­ä»£ {iteration:4d}: æŸå¤±={cost:.6f}, å‡†ç¡®ç‡={accuracy:.4f}")

            print("-" * 60)
            print("è®­ç»ƒå®Œæˆï¼")
            self._print_model_summary()

        else:
            # çº¯Pythonå®ç°
            n_samples = len(X_normalized)
            n_features = len(X_normalized[0])
            self.weights = [0.0] * n_features

            n_fraud = sum(y)
            print(f"\nå¼€å§‹è®­ç»ƒï¼ˆçº¯Pythonæ¨¡å¼ï¼‰...")
            print(f"æ ·æœ¬æ•°: {n_samples}, æ¬ºè¯ˆæ ·æœ¬: {n_fraud}")

            for iteration in range(self.max_iterations):
                # é¢„æµ‹
                y_pred_prob = []
                for x in X_normalized:
                    z = sum(x[j] * self.weights[j] for j in range(n_features)) + self.bias
                    y_pred_prob.append(sigmoid(z))

                # æŸå¤±
                epsilon = 1e-8
                cost = -sum(y_i * math.log(p + epsilon) + (1 - y_i) * math.log(1 - p + epsilon)
                           for y_i, p in zip(y, y_pred_prob)) / n_samples
                self.cost_history.append(cost)

                # æ¢¯åº¦
                for j in range(n_features):
                    dw = sum((p - y_i) * x[j] for p, y_i, x in zip(y_pred_prob, y, X_normalized)) / n_samples
                    self.weights[j] -= self.learning_rate * dw

                db = sum(p - y_i for p, y_i in zip(y_pred_prob, y)) / n_samples
                self.bias -= self.learning_rate * db

                if iteration % 100 == 0:
                    accuracy = sum(1 for p, y_i in zip(y_pred_prob, y)
                                 if (p >= self.threshold) == y_i) / n_samples
                    print(f"è¿­ä»£ {iteration:4d}: å‡†ç¡®ç‡={accuracy:.4f}")

    def predict_proba(self, X):
        """
        é¢„æµ‹æ¬ºè¯ˆæ¦‚ç‡
        è¿”å›: 0-1ä¹‹é—´çš„æ¦‚ç‡å€¼
        """
        is_single = isinstance(X[0], (int, float))
        if is_single:
            X = [X]

        X_normalized = self.standardize_features(X, fit=False)

        if HAS_NUMPY:
            X_normalized = np.array(X_normalized)
            z = np.dot(X_normalized, self.weights) + self.bias
            proba = 1 / (1 + np.exp(-np.clip(z, -500, 500)))
            return float(proba[0]) if is_single else proba.tolist()
        else:
            n_features = len(X_normalized[0])
            probas = []
            for x in X_normalized:
                z = sum(x[j] * self.weights[j] for j in range(n_features)) + self.bias
                probas.append(sigmoid(z))
            return probas[0] if is_single else probas

    def predict(self, X):
        """
        é¢„æµ‹ç±»åˆ«
        è¿”å›: 0(æ­£å¸¸) æˆ– 1(æ¬ºè¯ˆ)
        """
        probas = self.predict_proba(X)
        if isinstance(probas, float):
            return 1 if probas >= self.threshold else 0
        else:
            return [1 if p >= self.threshold else 0 for p in probas]

    def _print_model_summary(self):
        """æ‰“å°æ¨¡å‹æ‘˜è¦"""
        print("\næ¨¡å‹å‚æ•°æ‘˜è¦ï¼š")
        print("=" * 60)
        print(f"{'ç‰¹å¾åç§°':<20} {'æƒé‡':>15} {'å½±å“'}")
        print("-" * 60)

        if self.feature_names and HAS_NUMPY:
            weights_with_names = list(zip(self.feature_names, self.weights))
            weights_with_names.sort(key=lambda x: abs(x[1]), reverse=True)

            for name, weight in weights_with_names:
                influence = "å¢åŠ æ¬ºè¯ˆé£é™©" if weight > 0 else "é™ä½æ¬ºè¯ˆé£é™©"
                print(f"{name:<20} {weight:>15.4f}  {influence}")

        print(f"\n{'æˆªè·':<20} {self.bias:>15.4f}")
        print(f"{'åˆ†ç±»é˜ˆå€¼':<20} {self.threshold:>15.4f}")
        print("=" * 60)

    def evaluate(self, X, y_true):
        """
        å…¨é¢è¯„ä¼°æ¨¡å‹æ€§èƒ½
        è¿”å›: å‡†ç¡®ç‡, ç²¾ç¡®ç‡, å¬å›ç‡, F1åˆ†æ•°
        """
        y_pred = self.predict(X)
        if not isinstance(y_pred, list):
            y_pred = [y_pred]

        # è®¡ç®—æ··æ·†çŸ©é˜µ
        tp = sum(1 for pred, true in zip(y_pred, y_true) if pred == 1 and true == 1)  # çœŸé˜³æ€§
        tn = sum(1 for pred, true in zip(y_pred, y_true) if pred == 0 and true == 0)  # çœŸé˜´æ€§
        fp = sum(1 for pred, true in zip(y_pred, y_true) if pred == 1 and true == 0)  # å‡é˜³æ€§
        fn = sum(1 for pred, true in zip(y_pred, y_true) if pred == 0 and true == 1)  # å‡é˜´æ€§

        # è®¡ç®—æŒ‡æ ‡
        accuracy = (tp + tn) / len(y_true) if len(y_true) > 0 else 0
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'confusion_matrix': {'TP': tp, 'TN': tn, 'FP': fp, 'FN': fn}
        }


def generate_fraud_data(n_samples=1000, fraud_rate=0.05):
    """
    ç”Ÿæˆæ¨¡æ‹Ÿçš„ä¿¡ç”¨å¡äº¤æ˜“æ•°æ®

    æ¬ºè¯ˆäº¤æ˜“ç‰¹å¾ï¼š
    - é‡‘é¢é€šå¸¸è¾ƒå¤§
    - å¸¸åœ¨æ·±å¤œå‘ç”Ÿ
    - è·ç¦»ä¸Šæ¬¡äº¤æ˜“æ—¶é—´çŸ­ï¼ˆè¿ç»­å¤šç¬”ï¼‰
    - è·ç¦»å¸¸ç”¨åœ°ç‚¹è¿œ
    - é«˜é£é™©å•†æˆ·
    - å¢ƒå¤–äº¤æ˜“æ¦‚ç‡é«˜
    """
    print(f"ç”Ÿæˆæ¨¡æ‹Ÿäº¤æ˜“æ•°æ® (æ¬ºè¯ˆç‡: {fraud_rate*100:.1f}%)...")
    print("=" * 60)

    data = []
    n_fraud = int(n_samples * fraud_rate)
    n_normal = n_samples - n_fraud

    # ç”Ÿæˆæ­£å¸¸äº¤æ˜“
    for _ in range(n_normal):
        amount = random.uniform(10, 500)  # æ­£å¸¸é‡‘é¢ï¼š10-500å…ƒ
        hour = random.choice(list(range(8, 23)))  # ç™½å¤©äº¤æ˜“
        time_since_last = random.uniform(24, 168)  # è¾ƒé•¿æ—¶é—´é—´éš”
        distance_from_home = random.uniform(0, 20)  # å¸¸ç”¨åœ°ç‚¹é™„è¿‘
        merchant_risk = random.uniform(0, 0.3)  # ä½é£é™©å•†æˆ·
        is_foreign = 0  # å›½å†…äº¤æ˜“
        is_fraud = 0

        data.append([amount, hour, time_since_last, distance_from_home,
                    merchant_risk, is_foreign, is_fraud])

    # ç”Ÿæˆæ¬ºè¯ˆäº¤æ˜“
    for _ in range(n_fraud):
        amount = random.uniform(500, 5000)  # å¼‚å¸¸å¤§é¢
        hour = random.choice([0, 1, 2, 3, 4, 23])  # æ·±å¤œ
        time_since_last = random.uniform(0.1, 5)  # çŸ­æ—¶é—´å†…å¤šç¬”
        distance_from_home = random.uniform(50, 500)  # è¿œç¦»å¸¸ç”¨åœ°ç‚¹
        merchant_risk = random.uniform(0.5, 1.0)  # é«˜é£é™©å•†æˆ·
        is_foreign = random.choice([0, 1])  # å¯èƒ½å¢ƒå¤–
        is_fraud = 1

        data.append([amount, hour, time_since_last, distance_from_home,
                    merchant_risk, is_foreign, is_fraud])

    # æ‰“ä¹±æ•°æ®
    random.shuffle(data)
    return data


def demo_fraud_detection():
    """æ¼”ç¤ºå®Œæ•´çš„æ¬ºè¯ˆæ£€æµ‹é¡¹ç›®æµç¨‹"""
    print("\n" + "=" * 60)
    print("é¡¹ç›®æ¼”ç¤ºï¼šä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹ç³»ç»Ÿ")
    print("=" * 60)

    # 1. ç”Ÿæˆæ•°æ®
    data = generate_fraud_data(n_samples=2000, fraud_rate=0.05)

    # åˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾
    X = [row[:-1] for row in data]
    y = [row[-1] for row in data]

    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    split_index = int(len(X) * 0.8)
    X_train, X_test = X[:split_index], X[split_index:]
    y_train, y_test = y[:split_index], y[split_index:]

    print(f"\næ•°æ®é›†åˆ’åˆ†ï¼š")
    print(f"  è®­ç»ƒé›†: {len(X_train)} ç¬”äº¤æ˜“")
    print(f"  æµ‹è¯•é›†: {len(X_test)} ç¬”äº¤æ˜“")
    print(f"  è®­ç»ƒé›†æ¬ºè¯ˆç‡: {sum(y_train)/len(y_train)*100:.2f}%")

    # 2. è®­ç»ƒæ¨¡å‹
    model = FraudDetector(learning_rate=0.1, max_iterations=1000, threshold=0.5)
    feature_names = ['äº¤æ˜“é‡‘é¢', 'äº¤æ˜“æ—¶é—´', 'è·ä¸Šæ¬¡äº¤æ˜“', 'è·å¸¸ç”¨åœ°ç‚¹', 'å•†æˆ·é£é™©', 'æ˜¯å¦å¢ƒå¤–']
    model.fit(X_train, y_train, feature_names=feature_names)

    # 3. è¯„ä¼°æ¨¡å‹
    print("\n" + "=" * 60)
    print("æ¨¡å‹è¯„ä¼°")
    print("=" * 60)

    metrics_train = model.evaluate(X_train, y_train)
    print(f"\nè®­ç»ƒé›†æ€§èƒ½ï¼š")
    print(f"  å‡†ç¡®ç‡:   {metrics_train['accuracy']:.4f}")
    print(f"  ç²¾ç¡®ç‡:   {metrics_train['precision']:.4f} (é¢„æµ‹ä¸ºæ¬ºè¯ˆçš„äº¤æ˜“ä¸­çœŸæ­£æ˜¯æ¬ºè¯ˆçš„æ¯”ä¾‹)")
    print(f"  å¬å›ç‡:   {metrics_train['recall']:.4f} (å®é™…æ¬ºè¯ˆäº¤æ˜“ä¸­è¢«æ£€æµ‹å‡ºçš„æ¯”ä¾‹)")
    print(f"  F1åˆ†æ•°:   {metrics_train['f1']:.4f}")

    cm = metrics_train['confusion_matrix']
    print(f"\n  æ··æ·†çŸ©é˜µ:")
    print(f"    çœŸé˜³æ€§(TP): {cm['TP']} - æ­£ç¡®è¯†åˆ«çš„æ¬ºè¯ˆ")
    print(f"    çœŸé˜´æ€§(TN): {cm['TN']} - æ­£ç¡®è¯†åˆ«çš„æ­£å¸¸")
    print(f"    å‡é˜³æ€§(FP): {cm['FP']} - è¯¯åˆ¤ä¸ºæ¬ºè¯ˆçš„æ­£å¸¸äº¤æ˜“")
    print(f"    å‡é˜´æ€§(FN): {cm['FN']} - æ¼åˆ¤çš„æ¬ºè¯ˆäº¤æ˜“")

    metrics_test = model.evaluate(X_test, y_test)
    print(f"\næµ‹è¯•é›†æ€§èƒ½ï¼š")
    print(f"  å‡†ç¡®ç‡:   {metrics_test['accuracy']:.4f}")
    print(f"  ç²¾ç¡®ç‡:   {metrics_test['precision']:.4f}")
    print(f"  å¬å›ç‡:   {metrics_test['recall']:.4f}")
    print(f"  F1åˆ†æ•°:   {metrics_test['f1']:.4f}")

    # 4. é˜ˆå€¼è°ƒæ•´åˆ†æ
    print("\n" + "=" * 60)
    print("é˜ˆå€¼è°ƒæ•´åˆ†æ")
    print("=" * 60)
    print("\nè°ƒæ•´åˆ†ç±»é˜ˆå€¼å¯ä»¥å¹³è¡¡ç²¾ç¡®ç‡å’Œå¬å›ç‡ï¼š")
    print(f"{'é˜ˆå€¼':<8} {'ç²¾ç¡®ç‡':<10} {'å¬å›ç‡':<10} {'F1åˆ†æ•°':<10} {'å»ºè®®åœºæ™¯'}")
    print("-" * 70)

    thresholds = [0.3, 0.5, 0.7, 0.9]
    scenarios = [
        "å®½æ¾æ£€æµ‹ï¼Œå‡å°‘æ¼æŠ¥",
        "å¹³è¡¡æ€§èƒ½ï¼ˆé»˜è®¤ï¼‰",
        "ä¸¥æ ¼æ£€æµ‹ï¼Œå‡å°‘è¯¯æŠ¥",
        "æä¸¥æ ¼ï¼Œæœ€å°åŒ–è¯¯æŠ¥"
    ]

    for threshold, scenario in zip(thresholds, scenarios):
        model.threshold = threshold
        metrics = model.evaluate(X_test, y_test)
        print(f"{threshold:<8.1f} {metrics['precision']:<10.4f} {metrics['recall']:<10.4f} "
              f"{metrics['f1']:<10.4f} {scenario}")

    # æ¢å¤é»˜è®¤é˜ˆå€¼
    model.threshold = 0.5

    # 5. å®é™…æ¡ˆä¾‹æ£€æµ‹
    print("\n" + "=" * 60)
    print("å®é™…äº¤æ˜“æ£€æµ‹æ¡ˆä¾‹")
    print("=" * 60)

    test_cases = [
        {
            "æè¿°": "æ­£å¸¸ç™½å¤©è´­ç‰©",
            "ç‰¹å¾": [150, 14, 48, 5, 0.1, 0],
            "é¢„æœŸ": "æ­£å¸¸"
        },
        {
            "æè¿°": "æ·±å¤œå¤§é¢å¢ƒå¤–äº¤æ˜“",
            "ç‰¹å¾": [3000, 2, 0.5, 200, 0.8, 1],
            "é¢„æœŸ": "æ¬ºè¯ˆ"
        },
        {
            "æè¿°": "è¿ç»­å°é¢äº¤æ˜“",
            "ç‰¹å¾": [100, 10, 0.2, 10, 0.6, 0],
            "é¢„æœŸ": "å¯ç–‘"
        },
        {
            "æè¿°": "å‘¨æœ«ä¼‘é—²æ¶ˆè´¹",
            "ç‰¹å¾": [300, 18, 72, 15, 0.2, 0],
            "é¢„æœŸ": "æ­£å¸¸"
        }
    ]

    for i, case in enumerate(test_cases, 1):
        print(f"\næ¡ˆä¾‹ {i}: {case['æè¿°']}")
        features = case['ç‰¹å¾']
        print(f"  äº¤æ˜“é‡‘é¢: {features[0]:.0f}å…ƒ")
        print(f"  äº¤æ˜“æ—¶é—´: {features[1]}ç‚¹")
        print(f"  è·ä¸Šæ¬¡äº¤æ˜“: {features[2]:.1f}å°æ—¶")
        print(f"  è·å¸¸ç”¨åœ°ç‚¹: {features[3]:.0f}å…¬é‡Œ")
        print(f"  å•†æˆ·é£é™©: {features[4]:.2f}")
        print(f"  æ˜¯å¦å¢ƒå¤–: {'æ˜¯' if features[5] else 'å¦'}")

        prob = model.predict_proba(features)
        pred = model.predict(features)

        print(f"  æ¬ºè¯ˆæ¦‚ç‡: {prob:.4f}")
        print(f"  æ£€æµ‹ç»“æœ: {'ğŸš¨ æ¬ºè¯ˆ' if pred == 1 else 'âœ“ æ­£å¸¸'}")
        print(f"  é¢„æœŸç»“æœ: {case['é¢„æœŸ']}")

        # é£é™©ç­‰çº§
        if prob < 0.3:
            risk_level = "ä½é£é™©"
        elif prob < 0.7:
            risk_level = "ä¸­é£é™©"
        else:
            risk_level = "é«˜é£é™©"
        print(f"  é£é™©ç­‰çº§: {risk_level}")

    # 6. ä¸šåŠ¡å»ºè®®
    print("\n" + "=" * 60)
    print("ç³»ç»Ÿéƒ¨ç½²å»ºè®®")
    print("=" * 60)
    print(f"""
1. æ€§èƒ½æŒ‡æ ‡ç†è§£ï¼š
   - å½“å‰å¬å›ç‡: {metrics_test['recall']:.2%} - èƒ½æ£€æµ‹å‡º {metrics_test['recall']:.2%} çš„æ¬ºè¯ˆäº¤æ˜“
   - å½“å‰ç²¾ç¡®ç‡: {metrics_test['precision']:.2%} - é¢„è­¦äº¤æ˜“ä¸­ {metrics_test['precision']:.2%} ç¡®å®æ˜¯æ¬ºè¯ˆ
   - å‡é˜³æ€§ç‡: {metrics_test['confusion_matrix']['FP']/(metrics_test['confusion_matrix']['FP']+metrics_test['confusion_matrix']['TN']):.2%} - æ­£å¸¸äº¤æ˜“è¢«è¯¯åˆ¤çš„æ¯”ä¾‹

2. éƒ¨ç½²ç­–ç•¥ï¼š
   - é«˜é£é™©äº¤æ˜“(>0.7): ç«‹å³æ‹¦æˆªï¼Œäººå·¥å®¡æ ¸
   - ä¸­é£é™©äº¤æ˜“(0.3-0.7): çŸ­ä¿¡éªŒè¯æˆ–é¢å¤–è®¤è¯
   - ä½é£é™©äº¤æ˜“(<0.3): æ­£å¸¸æ”¾è¡Œï¼Œå¼‚æ­¥ç›‘æ§

3. æŒç»­ä¼˜åŒ–ï¼š
   - å®šæœŸç”¨æ–°æ•°æ®é‡æ–°è®­ç»ƒæ¨¡å‹
   - æ”¶é›†ç”¨æˆ·åé¦ˆæ”¹è¿›ç‰¹å¾å·¥ç¨‹
   - ç›‘æ§æ¨¡å‹æ€§èƒ½å˜åŒ–

4. æˆæœ¬æ”¶ç›Šï¼š
   - å‡é˜³æ€§æˆæœ¬: å®¢æˆ·ä½“éªŒä¸‹é™
   - å‡é˜´æ€§æˆæœ¬: å®é™…æ¬ºè¯ˆæŸå¤±
   - å»ºè®®æ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´é˜ˆå€¼
    """)


def interactive_detection():
    """äº¤äº’å¼æ¬ºè¯ˆæ£€æµ‹"""
    print("\n" + "=" * 60)
    print("äº¤äº’å¼æ¬ºè¯ˆæ£€æµ‹")
    print("=" * 60)

    # è®­ç»ƒæ¨¡å‹
    data = generate_fraud_data(n_samples=2000, fraud_rate=0.05)
    X = [row[:-1] for row in data]
    y = [row[-1] for row in data]

    model = FraudDetector(learning_rate=0.1, max_iterations=500)
    feature_names = ['äº¤æ˜“é‡‘é¢', 'äº¤æ˜“æ—¶é—´', 'è·ä¸Šæ¬¡äº¤æ˜“', 'è·å¸¸ç”¨åœ°ç‚¹', 'å•†æˆ·é£é™©', 'æ˜¯å¦å¢ƒå¤–']
    model.fit(X, y, feature_names=feature_names)

    print("\næ¨¡å‹è®­ç»ƒå®Œæˆï¼è¯·è¾“å…¥äº¤æ˜“ä¿¡æ¯è¿›è¡Œæ£€æµ‹ï¼š")
    print("ï¼ˆè¾“å…¥ 'q' é€€å‡ºï¼‰\n")

    while True:
        try:
            amount_input = input("äº¤æ˜“é‡‘é¢ï¼ˆå…ƒï¼‰: ")
            if amount_input.lower() == 'q':
                break
            amount = float(amount_input)

            hour = int(input("äº¤æ˜“æ—¶é—´ï¼ˆå°æ—¶ï¼Œ0-23ï¼‰: "))
            time_since_last = float(input("è·ä¸Šæ¬¡äº¤æ˜“æ—¶é—´ï¼ˆå°æ—¶ï¼‰: "))
            distance = float(input("è·å¸¸ç”¨åœ°ç‚¹è·ç¦»ï¼ˆå…¬é‡Œï¼‰: "))
            merchant_risk = float(input("å•†æˆ·é£é™©è¯„åˆ†ï¼ˆ0-1ï¼‰: "))
            is_foreign = int(input("æ˜¯å¦å¢ƒå¤–äº¤æ˜“ï¼ˆ0=å¦ï¼Œ1=æ˜¯ï¼‰: "))

            features = [amount, hour, time_since_last, distance, merchant_risk, is_foreign]
            prob = model.predict_proba(features)
            pred = model.predict(features)

            print(f"\n{'='*50}")
            print(f"æ¬ºè¯ˆæ¦‚ç‡: {prob:.4f}")
            print(f"æ£€æµ‹ç»“æœ: {'ğŸš¨ æ¬ºè¯ˆè­¦å‘Šï¼' if pred == 1 else 'âœ“ æ­£å¸¸äº¤æ˜“'}")
            if prob > 0.7:
                print(f"å»ºè®®æ“ä½œ: ç«‹å³æ‹¦æˆªï¼Œè”ç³»æŒå¡äººç¡®è®¤")
            elif prob > 0.3:
                print(f"å»ºè®®æ“ä½œ: å‘é€éªŒè¯çŸ­ä¿¡")
            else:
                print(f"å»ºè®®æ“ä½œ: æ­£å¸¸æ”¾è¡Œ")
            print(f"{'='*50}\n")

        except ValueError:
            print("è¾“å…¥é”™è¯¯ï¼Œè¯·è¾“å…¥æœ‰æ•ˆæ•°å­—ï¼\n")
        except KeyboardInterrupt:
            print("\n\nç¨‹åºå·²é€€å‡º")
            break


def main():
    """ä¸»å‡½æ•°"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        æœºå™¨å­¦ä¹ å®æˆ˜é¡¹ç›®ï¼šä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹ç³»ç»Ÿ            â•‘
â•‘        åŸºäºé€»è¾‘å›å½’çš„å®æ—¶é£é™©è¯„ä¼°                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    print("è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼ï¼š")
    print("1. å®Œæ•´æ¼”ç¤ºæ¨¡å¼ï¼ˆæ¨èï¼‰")
    print("2. äº¤äº’å¼æ£€æµ‹æ¨¡å¼")
    print("3. ä¸¤è€…éƒ½è¿è¡Œ")

    choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2/3): ").strip()

    if choice == '1':
        demo_fraud_detection()
    elif choice == '2':
        interactive_detection()
    elif choice == '3':
        demo_fraud_detection()
        interactive_detection()
    else:
        print("é€‰æ‹©æ— æ•ˆï¼Œè¿è¡Œé»˜è®¤æ¼”ç¤º...")
        demo_fraud_detection()

    print("\n" + "=" * 60)
    print("æ„Ÿè°¢ä½¿ç”¨æ¬ºè¯ˆæ£€æµ‹ç³»ç»Ÿï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
